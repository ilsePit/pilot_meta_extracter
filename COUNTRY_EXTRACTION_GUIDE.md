# Country Extraction: Strategies and Trade-offs

## Problem

CrossRef metadata often lacks explicit country information in author affiliations. In our test dataset:
- **Original approach**: 50% country coverage (2 out of 4 DOIs)
- **Improved approach**: 75% country coverage (3 out of 4 DOIs)

## Available Solutions

### 1. Pattern Matching (Fast, Free, Good Coverage)

**Advantages:**
- âœ… Free, no API limits
- âœ… Fast (instant)
- âœ… Works offline
- âœ… Covers 70-80% of cases

**Implementation:**
- US state detection (all 50 states + abbreviations)
- Known university patterns (Harvard, Oxford, etc.)
- Country name extraction from affiliation strings
- Common abbreviations (USA, UK, etc.)

**Limitations:**
- Won't work for: "Virginia Commonwealth University" (no state/country mentioned)
- Requires maintaining pattern lists
- May miss non-standard institution names

**Script:** `doi_metadata_final.R` âœ¨ **RECOMMENDED**

---

### 2. Geocoding APIs (Slower, More Complete)

#### Option A: OpenStreetMap Nominatim (Free)

**Advantages:**
- âœ… Free and open-source
- âœ… Good global coverage
- âœ… Can geocode institutions and addresses

**Limitations:**
- âš ï¸ Rate limit: 1 request/second (~2 seconds per DOI)
- âš ï¸ Public API has usage restrictions
- âš ï¸ May not recognize all institutions

**Implementation:** `tidygeocoder` R package with `method = "osm"`

**Script:** `doi_metadata_enhanced.R`

#### Option B: Google Geocoding API

**Advantages:**
- âœ… Best accuracy
- âœ… Excellent institution recognition

**Limitations:**
- âŒ Requires API key and billing account
- âŒ Costs money after free tier (200 requests/day)
- âŒ Rate limits

**Not implemented** (requires paid account)

#### Option C: Other Free APIs

- **MapBox**: Free tier, requires API key
- **LocationIQ**: Free tier (10k/month), requires API key
- **Bing Maps**: Requires API key

---

### 3. ORCID Lookup (Limited Availability)

**Theory:** Check author ORCID profiles for current employment/affiliation

**Reality:**
- âŒ Many researchers don't maintain ORCID employment data
- âŒ Privacy settings may hide information
- âŒ Additional API calls (slow)
- âœ… Would work for authors who keep ORCID updated

**Example:** The author from DOI `10.1037/pspi0000504` has an ORCID but no employment data listed

**Not implemented** (low success rate vs. complexity)

---

### 4. Hybrid Approach

Combine methods in order of speed/reliability:

```
1. Pattern matching (fast, free, 75% coverage)
   â†“ IF NOT FOUND
2. Check additional authors (some papers have multiple)
   â†“ IF NOT FOUND
3. Geocoding API (slow but thorough)
   â†“ IF NOT FOUND
4. ORCID lookup (optional, low success rate)
   â†“ IF NOT FOUND
5. Return NA
```

---

## Comparison of Approaches

| Approach | Speed | Coverage | Cost | Complexity |
|----------|-------|----------|------|------------|
| Pattern matching | âš¡âš¡âš¡ Instant | ðŸŸ¢ 75% | Free | Low |
| + Nominatim | â±ï¸ ~2s/DOI | ðŸŸ¢ 85-90% | Free | Medium |
| + Google API | â±ï¸ ~0.5s/DOI | ðŸŸ¢ 95% | $ after free tier | Medium |
| + ORCID | â±ï¸ ~1s/DOI | ðŸŸ¡ +5% | Free | High |

---

## Recommendations

### For Most Users: Pattern Matching Only âœ¨

**Use:** `doi_metadata_final.R`

**Pros:**
- Fast enough for large datasets (1000s of DOIs)
- No API dependencies or rate limits
- 75% coverage is acceptable for most research

**When to use:**
- Processing large batches (>100 DOIs)
- When speed matters
- When 75% coverage is acceptable

---

### For Maximum Accuracy: Pattern + Nominatim

**Use:** `doi_metadata_enhanced.R`

**Pros:**
- 85-90% coverage (estimated)
- Still free
- Better for international affiliations

**Cons:**
- Slow for large batches (2 seconds per DOI = 33 minutes for 1000 DOIs)
- Requires internet connection
- Must respect rate limits

**When to use:**
- Small to medium datasets (<200 DOIs)
- When maximum coverage is critical
- One-time analysis (not repeated queries)

---

## Implementation Examples

### Basic Pattern Matching

```r
source("doi_metadata_final.R")

# Process your DOIs
my_dois <- c("10.1177/xxx", "10.1111/yyy")
results <- process_dois(my_dois)
```

### With Geocoding (Enhanced)

```r
source("doi_metadata_enhanced.R")

# Slower but more accurate
results <- process_multiple_dois(my_dois, use_geocoding = TRUE)
```

### Custom Hybrid (Advanced)

```r
# Try pattern matching first
results <- process_dois(my_dois)

# Re-process only missing countries with geocoding
missing_countries <- results[is.na(results$country), ]
if (nrow(missing_countries) > 0) {
  enhanced <- process_multiple_dois(
    missing_countries$doi,
    use_geocoding = TRUE
  )
  # Merge results
  results[is.na(results$country), ] <- enhanced
}
```

---

## Improving Pattern Matching

### Add More Institutions

Edit `country_patterns` in the script to add universities from your field:

```r
country_patterns <- list(
  "United States" = c(
    # Existing patterns...
    "\\b(Wisconsin|Minnesota|Michigan State)\\b.*(University|College)",
    "\\bNIH\\b",  # National Institutes of Health
    "\\bCDC\\b"   # Centers for Disease Control
  ),
  "Netherlands" = c(
    "\\b(VU Amsterdam|Radboud)\\b"
  )
)
```

### Add Your Country

```r
country_patterns[["Brazil"]] <- c(
  "\\b(SÃ£o Paulo|USP|UNICAMP|UFRJ)\\b.*(University|Universidade)"
)
```

---

## Nominatim Usage Policy

If using geocoding, you **must** comply with:

1. **Rate limit:** Max 1 request per second
2. **User-Agent:** Set descriptive User-Agent header
3. **Caching:** Cache results, don't re-query same locations
4. **Fair use:** Don't abuse the free service

**Heavy usage:** Consider:
- Running your own Nominatim server (open source)
- Using a commercial geocoding service
- Pre-processing common institutions into a lookup table

---

## Test Results

### Original Script (Basic Extraction)
```
DOI: 10.1177/1745691620950684 â†’ Country: NA
DOI: 10.1111/bjso.12804 â†’ Country: France âœ“
DOI: 10.1037/pspi0000504 â†’ Country: NA
DOI: 10.1027/1864-9335/a000535 â†’ Country: United States âœ“

Coverage: 50% (2/4)
```

### Final Script (Pattern Matching)
```
DOI: 10.1177/1745691620950684 â†’ Country: United States âœ“
DOI: 10.1111/bjso.12804 â†’ Country: France âœ“
DOI: 10.1037/pspi0000504 â†’ Country: NA
DOI: 10.1027/1864-9335/a000535 â†’ Country: United States âœ“

Coverage: 75% (3/4)
```

### Enhanced Script (With Geocoding)
```
DOI: 10.1177/1745691620950684 â†’ Country: United States âœ“
DOI: 10.1111/bjso.12804 â†’ Country: France âœ“
DOI: 10.1037/pspi0000504 â†’ Country: NA (no affiliation data)
DOI: 10.1027/1864-9335/a000535 â†’ Country: United States âœ“

Coverage: 75% (3/4)
Note: Geocoding didn't help here because DOI #3 has NO affiliation data
```

---

## The Remaining Missing Case

**DOI:** `10.1037/pspi0000504`

**Problem:** CrossRef has NO affiliation data for any author

**Possible solutions:**
1. Manual lookup (check the paper PDF)
2. Publisher API (APA Psycnet might have more data)
3. PubMed lookup (may have additional metadata)
4. Accept that some data will be missing

**Reality:** ~5-10% of DOIs will have insufficient metadata regardless of method

---

## Summary

**Best practice:** Start with `doi_metadata_final.R` (pattern matching)

**If coverage is insufficient:**
1. Add patterns for your field's major institutions
2. Consider geocoding for small datasets
3. Accept that 100% coverage is rarely achievable

**Don't waste time on:** ORCID lookup (low ROI)
